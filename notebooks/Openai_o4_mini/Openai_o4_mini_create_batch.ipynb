{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6dfea876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import personalities_with_nationality\n",
    "import prompts\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "from openai import AsyncOpenAI\n",
    "from pprint import pprint\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "593f1fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file = \"data/data_with_nationality_1_openai.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f87fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = {\n",
    "    \"custom_id\": \"\",\n",
    "    \"method\": \"POST\",\n",
    "    \"url\": \"/v1/responses\",\n",
    "    \"body\": {\n",
    "        \"model\": \"o4-mini\",\n",
    "        \"input\": [\n",
    "            {\n",
    "                \"role\": \"developer\",\n",
    "                \"content\": \"\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"\",\n",
    "            },\n",
    "        ],\n",
    "        \"reasoning\": {\n",
    "    \"effort\": \"high\",\n",
    "    \"summary\": \"detailed\"\n",
    "  },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "428f5d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line: 1\n",
      "Line: 2\n",
      "Line: 3\n",
      "Line: 4\n",
      "Line: 5\n",
      "Line: 6\n",
      "Line: 7\n",
      "Line: 8\n",
      "Line: 9\n",
      "Line: 10\n",
      "Line: 11\n",
      "Line: 12\n",
      "Line: 13\n",
      "Line: 14\n",
      "Line: 15\n",
      "Line: 16\n",
      "Line: 17\n",
      "Line: 18\n",
      "Line: 19\n",
      "Line: 20\n",
      "Line: 21\n",
      "Line: 22\n",
      "Line: 23\n",
      "Line: 24\n",
      "Line: 25\n",
      "Line: 26\n",
      "Line: 27\n",
      "Line: 28\n",
      "Line: 29\n",
      "Line: 30\n",
      "Line: 31\n",
      "Line: 32\n",
      "Line: 33\n",
      "Line: 34\n",
      "Line: 35\n",
      "Line: 36\n",
      "Line: 37\n",
      "Line: 38\n",
      "Line: 39\n",
      "Line: 40\n",
      "Line: 41\n",
      "Line: 42\n",
      "Line: 43\n",
      "Line: 44\n",
      "Line: 45\n",
      "Line: 46\n",
      "Line: 47\n",
      "Line: 48\n",
      "Line: 49\n",
      "Line: 50\n",
      "Line: 51\n",
      "Line: 52\n",
      "Line: 53\n",
      "Line: 54\n",
      "Line: 55\n",
      "Line: 56\n",
      "Line: 57\n",
      "Line: 58\n",
      "Line: 59\n",
      "Line: 60\n",
      "Line: 61\n",
      "Line: 62\n",
      "Line: 63\n",
      "Line: 64\n",
      "Line: 65\n",
      "Line: 66\n",
      "Line: 67\n",
      "Line: 68\n",
      "Line: 69\n",
      "Line: 70\n",
      "Line: 71\n",
      "Line: 72\n",
      "Line: 73\n",
      "Line: 74\n",
      "Line: 75\n",
      "Line: 76\n",
      "Line: 77\n",
      "Line: 78\n",
      "Line: 79\n",
      "Line: 80\n",
      "Line: 81\n",
      "Line: 82\n",
      "Line: 83\n",
      "Line: 84\n",
      "Line: 85\n",
      "Line: 86\n",
      "Line: 87\n",
      "Line: 88\n",
      "Line: 89\n",
      "Line: 90\n",
      "Line: 91\n",
      "Line: 92\n",
      "Line: 93\n",
      "Line: 94\n",
      "Line: 95\n",
      "Line: 96\n",
      "Line: 97\n",
      "Line: 98\n",
      "Line: 99\n",
      "Line: 100\n",
      "Line: 101\n",
      "Line: 102\n",
      "Line: 103\n",
      "Line: 104\n",
      "Line: 105\n",
      "Line: 106\n",
      "Line: 107\n",
      "Line: 108\n",
      "Line: 109\n",
      "Line: 110\n",
      "Line: 111\n",
      "Line: 112\n",
      "Line: 113\n",
      "Line: 114\n",
      "Line: 115\n",
      "Line: 116\n",
      "Line: 117\n",
      "Line: 118\n",
      "Line: 119\n",
      "Line: 120\n",
      "Line: 121\n",
      "Line: 122\n",
      "Line: 123\n",
      "Line: 124\n",
      "Line: 125\n",
      "Line: 126\n",
      "Line: 127\n",
      "Line: 128\n",
      "Line: 129\n",
      "Line: 130\n",
      "Line: 131\n",
      "Line: 132\n",
      "Line: 133\n",
      "Line: 134\n",
      "Line: 135\n",
      "Line: 136\n",
      "Line: 137\n",
      "Line: 138\n",
      "Line: 139\n",
      "Line: 140\n",
      "Line: 141\n",
      "Line: 142\n",
      "Line: 143\n",
      "Line: 144\n",
      "Line: 145\n",
      "Line: 146\n",
      "Line: 147\n",
      "Line: 148\n",
      "Line: 149\n",
      "Line: 150\n",
      "Line: 151\n",
      "Line: 152\n",
      "Line: 153\n",
      "Line: 154\n",
      "Line: 155\n",
      "Line: 156\n",
      "Line: 157\n",
      "Line: 158\n",
      "Line: 159\n",
      "Line: 160\n",
      "Line: 161\n",
      "Line: 162\n",
      "Line: 163\n",
      "Line: 164\n",
      "Line: 165\n",
      "Line: 166\n",
      "Line: 167\n",
      "Line: 168\n",
      "Line: 169\n",
      "Line: 170\n",
      "Line: 171\n",
      "Line: 172\n",
      "Line: 173\n",
      "Line: 174\n",
      "Line: 175\n",
      "Line: 176\n",
      "Line: 177\n",
      "Line: 178\n",
      "Line: 179\n",
      "Line: 180\n",
      "Line: 181\n",
      "Line: 182\n",
      "Line: 183\n",
      "Line: 184\n",
      "Line: 185\n",
      "Line: 186\n",
      "Line: 187\n",
      "Line: 188\n",
      "Line: 189\n",
      "Line: 190\n",
      "Line: 191\n",
      "Line: 192\n",
      "Line: 193\n",
      "Line: 194\n",
      "Line: 195\n",
      "Line: 196\n",
      "Line: 197\n",
      "Line: 198\n",
      "Line: 199\n",
      "Line: 200\n",
      "Line: 201\n",
      "Line: 202\n",
      "Line: 203\n",
      "Line: 204\n",
      "Line: 205\n",
      "Line: 206\n",
      "Line: 207\n",
      "Line: 208\n",
      "Line: 209\n",
      "Line: 210\n",
      "Line: 211\n",
      "Line: 212\n",
      "Line: 213\n",
      "Line: 214\n",
      "Line: 215\n",
      "Line: 216\n",
      "Line: 217\n",
      "Line: 218\n",
      "Line: 219\n",
      "Line: 220\n",
      "Line: 221\n",
      "Line: 222\n",
      "Line: 223\n",
      "Line: 224\n",
      "Line: 225\n",
      "Line: 226\n",
      "Line: 227\n",
      "Line: 228\n",
      "Line: 229\n",
      "Line: 230\n",
      "Line: 231\n",
      "Line: 232\n",
      "Line: 233\n",
      "Line: 234\n",
      "Line: 235\n",
      "Line: 236\n",
      "Line: 237\n",
      "Line: 238\n",
      "Line: 239\n",
      "Line: 240\n",
      "Line: 241\n",
      "Line: 242\n",
      "Line: 243\n",
      "Line: 244\n",
      "Line: 245\n",
      "Line: 246\n",
      "Line: 247\n",
      "Line: 248\n",
      "Line: 249\n",
      "Line: 250\n",
      "Line: 251\n",
      "Line: 252\n",
      "Line: 253\n",
      "Line: 254\n",
      "Line: 255\n",
      "Line: 256\n",
      "Line: 257\n",
      "Line: 258\n",
      "Line: 259\n",
      "Line: 260\n",
      "Line: 261\n",
      "Line: 262\n",
      "Line: 263\n",
      "Line: 264\n",
      "Line: 265\n",
      "Line: 266\n",
      "Line: 267\n",
      "Line: 268\n",
      "Line: 269\n",
      "Line: 270\n",
      "Line: 271\n",
      "Line: 272\n",
      "Line: 273\n",
      "Line: 274\n",
      "Line: 275\n",
      "Line: 276\n",
      "Line: 277\n",
      "Line: 278\n",
      "Line: 279\n",
      "Line: 280\n",
      "Line: 281\n",
      "Line: 282\n",
      "Line: 283\n",
      "Line: 284\n",
      "Line: 285\n",
      "Line: 286\n",
      "Line: 287\n",
      "Line: 288\n",
      "Line: 289\n",
      "Line: 290\n",
      "Line: 291\n",
      "Line: 292\n",
      "Line: 293\n",
      "Line: 294\n",
      "Line: 295\n",
      "Line: 296\n",
      "Line: 297\n",
      "Line: 298\n",
      "Line: 299\n",
      "Line: 300\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(parquet_file, engine='pyarrow')\n",
    "\n",
    "target_columns = ['far_right_EN', 'far_right_PL', 'far_right_RU', 'mod_cons_EN', 'mod_cons_PL', 'mod_cons_RU',\n",
    "    'prog_left_EN', 'prog_left_PL', 'prog_left_RU', 'centrist_EN', 'centrist_PL', 'centrist_RU']\n",
    "    \n",
    "    \n",
    "# Process rows one by one\n",
    "for index, row in df.iterrows():\n",
    "    print(f'Line: {index}')\n",
    "    system_prompts = list()\n",
    "    user_prompts = list()\n",
    "    cols_to_process = list()\n",
    "    for target_col in target_columns:\n",
    "        # Skip if cell is None already processed\n",
    "        if not pd.isna(row['OPENAI_' + target_col + '_reasoning']) and not pd.isna(row['OPENAI_' + target_col + '_answer']):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            with open('data/test_batch_1.jsonl', 'a') as f:\n",
    "                new_item = item.copy()\n",
    "                new_item['custom_id'] = f\"{target_col}_{index}\"\n",
    "                if target_col[-2:] == 'EN':\n",
    "                    new_item['body']['input'][0]['content'] = prompts.system_prompt_EN\n",
    "                    new_item['body']['input'][1]['content'] = prompts.user_text_EN.replace('{personality}', getattr(personalities_with_nationality, target_col)).replace('{tweet}', row['Text_EN'])\n",
    "                elif target_col[-2:] == 'PL':\n",
    "                    new_item['body']['input'][0]['content'] = prompts.system_prompt_PL\n",
    "                    new_item['body']['input'][1]['content'] = prompts.user_text_EN.replace('{personality}', getattr(personalities_with_nationality, target_col)).replace('{tweet}', row['Text_PL'])\n",
    "                elif target_col[-2:] == 'RU':\n",
    "                    new_item['body']['input'][0]['content'] = prompts.system_prompt_RU\n",
    "                    new_item['body']['input'][1]['content'] = prompts.user_text_EN.replace('{personality}', getattr(personalities_with_nationality, target_col)).replace('{tweet}', row['Text_RU'])\n",
    "                else:\n",
    "                    raise Exception\n",
    "                \n",
    "\n",
    "\n",
    "                json_line = json.dumps(new_item, ensure_ascii=False)\n",
    "                f.write(json_line + '\\n')\n",
    "            \n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {target_col} at index {index}: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
